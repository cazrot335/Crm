import express from 'express';
import fetch from 'node-fetch';
import dotenv from 'dotenv';
import cors from 'cors';
import { exec } from 'child_process';
import fs from 'fs';
import path, { dirname } from 'path';
import { fileURLToPath } from 'url';

dotenv.config();

const __dirname = dirname(fileURLToPath(import.meta.url));

const app = express();
app.use(cors());
app.use(express.json());

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const HF_API_KEY = process.env.HF_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const APIFY_API_KEY = process.env.APIFY_API_KEY;
const NEWS_API_KEY = process.env.NEWS_API_KEY; // Ensure this is configured for a search API or news API that you intend to use.

// Global (or more accurately, server-side persistent) variable to store last scraped URL and content
let lastScrapedData = { url: null, content: null, timestamp: null, status: 'idle' };

const AI_KNOWLEDGE_CUTOFF = "early 2024";

function isClearlyIrrelevant(text) {
  const lowerCaseText = text.toLowerCase();
  const irrelevantPatterns = [
    /weather|temperature/i,
    /friend|dating|relationship/i,
    /cook|recipe|kitchen|food/i,
    /play|game|movies|music/i,
    /joke|funny|meme/i,
  ];
  return irrelevantPatterns.some(pat => pat.test(lowerCaseText));
}

// ======================= NEW FUNCTION FOR WEB SEARCH =======================
async function performWebSearch(query) {
    console.log(`üåê Performing web search for: "${query}"`);
    try {
        // This is a placeholder using NEWS_API. For a general web search, you'd use a different API.
        // Example with News API: Search for articles related to the query
        const searchUrl = `https://newsapi.org/v2/everything?q=${encodeURIComponent(query)}&language=en&sortBy=relevancy&apiKey=${NEWS_API_KEY}`;
        const response = await fetch(searchUrl);
        const data = await response.json();

        if (data.status === 'ok' && data.articles && data.articles.length > 0) {
            let searchResults = "Here are some recent search results:\n\n";
            data.articles.slice(0, 3).forEach((article, index) => { // Get top 3 articles
                searchResults += `**Result ${index + 1}:**\n`;
                searchResults += `Title: ${article.title}\n`;
                searchResults += `Source: ${article.source.name}\n`;
                searchResults += `URL: ${article.url}\n`;
                searchResults += `Description: ${article.description || 'No description available.'}\n\n`;
            });
            return searchResults;
        } else {
            return `No recent news or web results found for "${query}" through the integrated search.`;
        }
    } catch (error) {
        console.error("Error during web search:", error);
        return `I encountered an error while trying to perform a web search for "${query}".`;
    }
}
// ===================== END NEW FUNCTION ==================================

// API Endpoint for Real-Time Information (Time)
app.get('/api/time', (req, res) => {
    const now = new Date();
    const options = {
        weekday: 'long', year: 'numeric', month: 'long', day: 'numeric',
        hour: '2-digit', minute: '2-digit', second: '2-digit',
        timeZoneName: 'short'
    };
    const formattedTime = now.toLocaleString('en-IN', options);
    const currentTimeZone = Intl.DateTimeFormat().resolvedOptions().timeZone;

    res.json({
        currentTime: formattedTime,
        timeZone: currentTimeZone || "Unknown"
    });
});


app.post('/api/chat', async (req, res) => {
  try {
    const { messages, model, scrape } = req.body;
    const userInput = messages[messages.length - 1]?.content;
    const urlRegex = /(https?:\/\/[^\s]+)/g;
    const urls = userInput.match(urlRegex);

    const lowerCaseInput = userInput.toLowerCase().trim();

    // 1. Handle Time-related Queries (still specific as it needs external tool)
    if (lowerCaseInput.includes("time") && (lowerCaseInput.includes("current") || lowerCaseInput.includes("what is") || lowerCaseInput.includes("now") || lowerCaseInput.includes("update"))) {
        console.log("‚è∞ Time query detected. Fetching real-time data.");
        try {
            const timeResponse = await fetch('http://localhost:3000/api/time');
            const timeData = await timeResponse.json();

            const timeContext = `The current date and time is: ${timeData.currentTime} (${timeData.timeZone}).`;
            // Send the context to the AI model to formulate a natural response
            const messagesForAI = [
                messages[0], // Keep the system prompt
                { role: "user", content: `The user asked for the current time. Respond with the following information: ${timeContext}. Keep it concise and friendly.` }
            ];
            
            let aiResponseContent = '‚ö†Ô∏è Could not get a response for time query.';
            if (model === "gemini") {
                const geminiContents = [];
                let lastRole = '';
                for (const msg of messagesForAI) {
                    const roleForGemini = msg.role === 'system' ? 'user' : (msg.role === 'assistant' ? 'model' : msg.role);
                    if (roleForGemini === lastRole && lastRole !== 'system') {
                        geminiContents[geminiContents.length - 1].parts.push({ text: msg.content });
                    } else {
                        geminiContents.push({ role: roleForGemini, parts: [{ text: msg.content }] });
                    }
                    lastRole = roleForGemini;
                }
                const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents: geminiContents })
                });
                const geminiData = await geminiResponse.json();
                aiResponseContent = geminiData.candidates?.[0]?.content?.parts[0]?.text || '‚ö†Ô∏è No response from Gemini for time query.';
            } else if (model === "gpt-3.5") {
                const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${OPENAI_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        model: "gpt-3.5-turbo",
                        messages: messagesForAI,
                        temperature: 0.7
                    })
                });
                const openaiData = await openaiResponse.json();
                aiResponseContent = openaiData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from OpenAI for time query.';
            } else { // DeepSeek
                const deepseekResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${HF_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        messages: messagesForAI,
                        model: "deepseek/deepseek-r1:free",
                        stream: false
                    })
                });
                const deepseekData = await deepseekResponse.json();
                aiResponseContent = deepseekData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from DeepSeek for time query.';
            }
            return res.json({ choices: [{ message: { content: aiResponseContent } }] });

        } catch (timeError) {
            console.error("‚ùå Error fetching real-time time:", timeError);
            return res.json({ choices: [{ message: { content: "I'm sorry, I couldn't fetch the current time right now." } }] });
        }
    }

    // 2. Handle Queries for Future/Real-time Knowledge Limitations (still specific)
    const academicKeywords = ["visa", "scholarship", "ranking", "policy", "requirements", "admission", "program", "university", "college", "course", "study abroad"];
    const realtimeIndicators = ["latest", "recent", "news", "updates", "current", "as of now", "what's new"];
    
    const requiresRealtimeSearch = realtimeIndicators.some(kw => lowerCaseInput.includes(kw)) &&
                                   academicKeywords.some(kw => lowerCaseInput.includes(kw)) &&
                                   !(scrape || (urls && urls.length > 0)); // Don't search if a URL is provided

    if (requiresRealtimeSearch) {
        console.log("üîç Real-time academic search query detected. Initiating web search.");
        let searchResultsContent = await performWebSearch(userInput);

        const messagesForAI = [
            messages[0], // System prompt
            { role: "user", content: `The user asked for current information related to "${userInput}". I performed a web search and found the following:
            """
            ${searchResultsContent}
            """
            Please summarize the key academic-related points from these results and provide an answer to the user's query. If no relevant results were found, inform the user accordingly. Make sure to cite the sources found in the search results (if any are presented by the search function, e.g., article URLs).` }
        ];

        let aiResponseContent = '‚ö†Ô∏è Could not get a response from web search analysis.';
        // Use the selected model to process search results
        if (model === "gemini") {
            const geminiContents = [];
            let lastRole = '';
            for (const msg of messagesForAI) {
                const roleForGemini = msg.role === 'system' ? 'user' : (msg.role === 'assistant' ? 'model' : msg.role);
                if (roleForGemini === lastRole && lastRole !== 'system') {
                    geminiContents[geminiContents.length - 1].parts.push({ text: msg.content });
                } else {
                    geminiContents.push({ role: roleForGemini, parts: [{ text: msg.content }] });
                }
                lastRole = roleForGemini;
            }
            const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ contents: geminiContents })
            });
            const geminiData = await geminiResponse.json();
            aiResponseContent = geminiData.candidates?.[0]?.content?.parts[0]?.text || '‚ö†Ô∏è No response from Gemini for web search summary.';
        } else if (model === "gpt-3.5") {
            const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: "gpt-3.5-turbo",
                    messages: messagesForAI,
                    temperature: 0.7
                })
            });
            const openaiData = await openaiResponse.json();
            aiResponseContent = openaiData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from OpenAI for web search summary.';
        } else { // DeepSeek
            const deepseekResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${HF_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    messages: messagesForAI,
                    model: "deepseek/deepseek-r1:free",
                    stream: false
                })
            });
            const deepseekData = await deepseekResponse.json();
            aiResponseContent = deepseekData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from DeepSeek for web search summary.';
        }
        return res.json({ choices: [{ message: { content: aiResponseContent } }] });
    }

    // Inform about knowledge cutoff if a future/real-time keyword is present without a specific URL or web search trigger
    const futureOrRealtimeKeywords = ["2025", "2026", "future", "real-time", "live", "up-to-the-minute", "as of now"];
    const hasFutureKeyword = futureOrRealtimeKeywords.some(kw => lowerCaseInput.includes(kw));

    if (hasFutureKeyword && !requiresRealtimeSearch && !(scrape || (urls && urls.length > 0))) {
        return res.json({
            choices: [{
                message: {
                    content: `My knowledge base is based on information up to ${AI_KNOWLEDGE_CUTOFF}. I cannot predict future policies or provide true real-time updates unless that information is available on a specific website you provide for scraping, or if I can find it through a general web search. Would you like me to try a general web search for "${userInput}"?`
                }
            }]
        });
    }
    
    // 3. Handle Contextual Updates after a scrape (still specific)
    const contextualUpdateKeywords = ["update", "news", "current", "latest", "changes"];
    const refersToPreviousSite = lowerCaseInput.includes("this website") || lowerCaseInput.includes("above website") || lowerCaseInput.includes("the site") || lowerCaseInput.includes("the college") || lowerCaseInput.includes("from above");

    if (
        lastScrapedData.url &&
        lastScrapedData.content &&
        contextualUpdateKeywords.some(kw => lowerCaseInput.includes(kw)) &&
        refersToPreviousSite
    ) {
        console.log("üîç Contextual update query detected for last scraped site.");
        const updateAnalysisPrompt = `The user is asking for updates or new information regarding the content previously scraped from ${lastScrapedData.url}. Analyze the following text and identify any recent news, announcements, events, or changes that could be considered "updates".

        **Important Constraint**: You can only provide information *found within this text*. If the content does not contain clear "updates as of now" or very recent information, please state that based *only* on the text provided. Do not invent real-time access. Focus on educational, institutional, or event-related updates. Limit your response to 400 words.

        Previously Scraped Content:
        """
        ${lastScrapedData.content}
        """`;

        const messagesForAI = [
            messages[0], // System prompt
            { role: "user", content: updateAnalysisPrompt }
        ];

        let aiResponseContent = '‚ö†Ô∏è Could not analyze for updates.';

        if (model === "gemini") {
            const geminiContents = [];
            let lastRole = '';
            for (const msg of messagesForAI) {
                const roleForGemini = msg.role === 'system' ? 'user' : (msg.role === 'assistant' ? 'model' : msg.role);
                if (roleForGemini === lastRole && lastRole !== 'system') {
                    geminiContents[geminiContents.length - 1].parts.push({ text: msg.content });
                    } else {
                    geminiContents.push({ role: roleForGemini, parts: [{ text: msg.content }] });
                }
                lastRole = roleForGemini;
            }
            
            const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ contents: geminiContents })
            });
            const geminiData = await geminiResponse.json();
            aiResponseContent = geminiData.candidates?.[0]?.content?.parts[0]?.text || '‚ö†Ô∏è No response from Gemini API for update analysis.';
        } else if (model === "gpt-3.5") {
            const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: "gpt-3.5-turbo",
                    messages: messagesForAI,
                    temperature: 0.7
                })
            });
            const openaiData = await openaiResponse.json();
            aiResponseContent = openaiData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from OpenAI API for update analysis.';
        } else { // Default to DeepSeek
            const deepseekResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${HF_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    messages: messagesForAI,
                    model: "deepseek/deepseek-r1:free",
                    stream: false
                })
            });
            const deepseekData = await deepseekResponse.json();
            aiResponseContent = deepseekData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from DeepSeek API for analysis.';
        }

        return res.json({
            choices: [{ message: { content: `‚ú® Analyzing the content from ${lastScrapedData.url} for updates:\n\n${aiResponseContent}` } }]
        });
    }


    // 4. Handle Meta-Commands for Previous Output Refining
    const refineOutputPhrases = ["specific", "important", "detail", "details", "summarize", "concise", "extract", "shorten", "elaborate", "explain"];
    const refersToLastOutput = lowerCaseInput.includes("from the above") || lowerCaseInput.includes("this summary") || lowerCaseInput.includes("from your last answer") || lowerCaseInput.includes("the above");

    if (refineOutputPhrases.some(phrase => lowerCaseInput.includes(phrase)) && refersToLastOutput) {
        if (messages.length >= 2) {
            const previousBotReply = messages[messages.length - 2]?.content;

            if (previousBotReply && previousBotReply.length > 50) {
                console.log("üîç Refining previous output based on user request.");
                const refinementPrompt = `The user has asked to ${lowerCaseInput.replace('from the above', '').replace('this summary', '').replace('from your last answer', '').trim()}. Please refine the following text accordingly, focusing on academic/educational relevance. Keep it concise and impactful.

                Text to refine:
                """
                ${previousBotReply}
                """`;

                const messagesForAI = [
                    messages[0],
                    { role: "user", content: refinementPrompt }
                ];

                let aiResponseContent = '‚ö†Ô∏è Could not refine the previous information.';

                if (model === "gemini") {
                    const geminiContents = [];
                    let lastRole = '';
                    for (const msg of messagesForAI) {
                        const roleForGemini = msg.role === 'system' ? 'user' : (msg.role === 'assistant' ? 'model' : msg.role);
                        if (roleForGemini === lastRole && lastRole !== 'system') {
                            geminiContents[geminiContents.length - 1].parts.push({ text: msg.content });
                        } else {
                            geminiContents.push({ role: roleForGemini, parts: [{ text: msg.content }] });
                        }
                        lastRole = roleForGemini;
                    }
                    const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ contents: geminiContents })
                    });
                    const geminiData = await geminiResponse.json();
                    aiResponseContent = geminiData.candidates?.[0]?.content?.parts[0]?.text || '‚ö†Ô∏è No response from Gemini API for refinement.';
                } else if (model === "gpt-3.5") {
                    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${OPENAI_API_KEY}`,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            model: "gpt-3.5-turbo",
                            messages: messagesForAI,
                            temperature: 0.7
                        })
                    });
                    const openaiData = await openaiResponse.json();
                    aiResponseContent = openaiData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from OpenAI API for refinement.';
                } else { // DeepSeek
                    const deepseekResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${HF_API_KEY}`,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            messages: messagesForAI,
                            model: "deepseek/deepseek-r1:free",
                            stream: false
                        })
                    });
                    const deepseekData = await deepseekResponse.json();
                    aiResponseContent = deepseekData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from DeepSeek API for refinement.';
                }

                return res.json({
                    choices: [{ message: { content: `‚ú® Here's the refined information:\n\n${aiResponseContent}` } }]
                });
            }
        }
    }


    // 5. Handle Scraping if a URL is present or explicitly requested
    if (scrape || (urls && urls.length > 0)) {
      console.log("üîó Scraping triggered");
      const targetUrl = scrape || urls[0];
      let scrapedContent = '';

      try {
        if (APIFY_API_KEY) { // Try Apify first if key is available
            console.log("Attempting Apify scrape...");
            const runResponse = await fetch(`https://api.apify.com/v2/acts/apify~website-content-crawler/runs?token=${APIFY_API_KEY}`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                startUrls: [{ url: targetUrl }],
                maxCrawlPages: 5,
                maxCrawlDepth: 2,
              })
            });

            const runData = await runResponse.json();
            if (!runData.data || !runData.data.id) {
              console.error("Apify actor response:", runData);
              throw new Error('Apify actor run failed to start');
            }

            const runId = runData.data.id;
            let status = 'RUNNING';

            let attempts = 0;
            const maxAttempts = 15; // Increased attempts for longer scrapes
            while ((status === 'RUNNING' || status === 'READY') && attempts < maxAttempts) {
              console.log(`‚è≥ Waiting for Apify run... (Attempt ${attempts + 1}/${maxAttempts})`);
              await new Promise(r => setTimeout(r, 6000)); // Increased wait time
              const statusResponse = await fetch(`https://api.apify.com/v2/actor-runs/${runId}?token=${APIFY_API_KEY}`);
              const statusData = await statusResponse.json();
              status = statusData.data.status;
              attempts++;
            }

            if (status !== 'SUCCEEDED') {
                throw new Error(`Apify scraping did not succeed. Status: ${status}`);
            }
            
            const datasetResponse = await fetch(`https://api.apify.com/v2/actor-runs/${runId}/dataset/items?token=${APIFY_API_KEY}`);
            const datasetItems = await datasetResponse.json();

            scrapedContent = datasetItems.map(item => item.text || '').join('\n\n').slice(0, 8000); // Increased content limit
            console.log("‚úÖ Apify scrape successful.");

        } else {
            throw new Error("APIFY_API_KEY not configured. Falling back to direct fetch.");
        }
      } catch (apifyError) {
        console.warn("‚ö†Ô∏è Apify failed or not configured, falling back to direct fetch:", apifyError.message);

        const fallbackResponse = await fetch(targetUrl, {
          method: 'GET',
          headers: { 'User-Agent': 'Mozilla/5.0' }
        });
        const html = await fallbackResponse.text();

        scrapedContent = html
          .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
          .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
          .replace(/<[^>]+>/g, '')
          .replace(/\s+/g, ' ')
          .trim()
          .slice(0, 5000);
        console.log("‚úÖ Fallback direct fetch successful.");
      }

      // Store the last scraped data for contextual follow-ups
      lastScrapedData = {
          url: targetUrl,
          content: scrapedContent,
          timestamp: new Date()
      };

      // Send scraped content to the AI model for initial summary
      if (scrapedContent) {
        console.log("Sending scraped content to AI for initial summary...");

        const analysisPrompt = `The following content was scraped from ${targetUrl}. Please analyze it and provide a concise, structured summary focusing on academic, educational, and institutional details relevant to a student or counselor. Include information about courses, admissions, fees, faculty, facilities, or any other relevant details for international study, if available. Prioritize clear, bulleted lists or short paragraphs for readability. If the content is not clearly academic or related to study abroad, state that. Limit your response to 500 words.

        Scraped Content:
        """
        ${scrapedContent}
        """`;

        const messagesForAI = [
            messages[0], // System prompt
            { role: "user", content: analysisPrompt }
        ];

        let aiResponseContent = '‚ö†Ô∏è Could not analyze scraped content.';

        if (model === "gemini") {
            const geminiContents = [];
            let lastRole = '';
            for (const msg of messagesForAI) {
                const roleForGemini = msg.role === 'system' ? 'user' : (msg.role === 'assistant' ? 'model' : msg.role);
                if (roleForGemini === lastRole && lastRole !== 'system') {
                    geminiContents[geminiContents.length - 1].parts.push({ text: msg.content });
                } else {
                    geminiContents.push({ role: roleForGemini, parts: [{ text: msg.content }] });
                }
                lastRole = roleForGemini;
            }
            
            const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ contents: geminiContents })
            });
            const geminiData = await geminiResponse.json();
            aiResponseContent = geminiData.candidates?.[0]?.content?.parts[0]?.text || '‚ö†Ô∏è No response from Gemini API for analysis.';
        } else if (model === "gpt-3.5") {
            const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: "gpt-3.5-turbo",
                    messages: messagesForAI,
                    temperature: 0.7
                })
            });
            const openaiData = await openaiResponse.json();
            aiResponseContent = openaiData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from OpenAI API for analysis.';
        } else { // Default to DeepSeek
            const deepseekResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${HF_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    messages: messagesForAI,
                    model: "deepseek/deepseek-r1:free",
                    stream: false
                })
            });
            const deepseekData = await deepseekResponse.json();
            aiResponseContent = deepseekData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from DeepSeek API for analysis.';
        }

        return res.json({
          choices: [{ message: { content: `‚ú® Here's a summary of the content from ${targetUrl}:\n\n${aiResponseContent}` } }]
        });

      } else {
          return res.json({
              choices: [{ message: { content: `I'm sorry, I couldn't retrieve any content from ${targetUrl}. üòî

This can sometimes happen if:
* The website has strong anti-scraping measures.
* The page requires a login or has a complex structure.
* The URL is incorrect or the page is empty.

**What you can try:**
Could you please provide a different, more direct link? The main admissions or program page often works best.` } }]
          });
      }
    }

    if (isClearlyIrrelevant(userInput)) {
      console.log("üö´ Detected irrelevant query. Blocking and sending fallback message.");
      return res.json({
        choices: [{
          message: {
            content: "My purpose is to assist with study abroad and academic counseling. I can't help with topics like cooking or the weather. How can I help you with universities, visas, or applications today?"
          }
        }]
      });
    }

    // This is the main path for *general academic queries* and also general conversation (greetings, acknowledgments, negative closures, help requests)
    // that require AI processing. The LLM will now handle these contextually.
    if (model === "gemini") {
      console.log("üîó Using Gemini API for general chat");
      const geminiContents = [];
      let lastRole = '';
      // Correctly format for Gemini: alternate between 'user' and 'model', and handle system prompt
      messages.forEach(msg => {
          const roleForGemini = msg.role === 'system' ? 'user' : (msg.role === 'assistant' ? 'model' : msg.role);
          
          // Gemini API requires roles to alternate. If the last role was the same, merge content.
          if (geminiContents.length > 0 && geminiContents[geminiContents.length - 1].role === roleForGemini) {
              geminiContents[geminiContents.length - 1].parts.push({ text: msg.content });
          } else {
              geminiContents.push({ role: roleForGemini, parts: [{ text: msg.content }] });
          }
      });

      const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ contents: geminiContents })
      });

      const geminiData = await geminiResponse.json();
      if (!geminiResponse.ok || geminiData.error) {
        console.error("Gemini API Error:", geminiData.error);
        return res.status(500).json({ error: geminiData.error?.message || 'Gemini API Error' });
      }

      const reply = geminiData.candidates?.[0]?.content?.parts.map(part => part.text).join('') || '‚ö†Ô∏è No response from Gemini API.';
      return res.json({ choices: [{ message: { content: reply } }] });
    }

    if (model === "gpt-3.5") {
      console.log("üîó Using GPT-3.5 API for general chat");
      const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages,
          temperature: 0.7
        })
      });

      const openaiData = await openaiResponse.json();
      const reply = openaiData.choices?.[0]?.message?.content || '‚ö†Ô∏è No response from OpenAI API.';
      return res.json({ choices: [{ message: { content: reply } }] });
    }

    // Default to DeepSeek for general chat if no other model matches
    console.log("üîó Using DeepSeek API for general chat");
    const deepseekResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${HF_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        messages,
        model: "deepseek/deepseek-r1:free",
        stream: false
      })
    });

    const deepseekData = await deepseekResponse.json();
    return res.json(deepseekData);

  } catch (err) {
    console.error("‚ùå Backend error:", err);
    res.status(500).json({ error: err.message || 'API call failed' });
  }
});

app.listen(3000, () => console.log('‚úÖ Server running on http://localhost:3000'));